{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from lines import *\n",
    "import pytesseract\n",
    "\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'  # Adjust the path as per your Tesseract installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('cropped/AA AT-096-[0].jpg', 0)  # 0 loads the image in grayscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def line_intersection(line1, line2):\n",
    "    xdiff = (line1[0][0] - line1[1][0], line2[0][0] - line2[1][0])\n",
    "    ydiff = (line1[0][1] - line1[1][1], line2[0][1] - line2[1][1])\n",
    "\n",
    "    def det(a, b):\n",
    "        return a[0] * b[1] - a[1] * b[0]\n",
    "\n",
    "    div = det(xdiff, ydiff)\n",
    "    if div == 0:\n",
    "       raise Exception('lines do not intersect')\n",
    "\n",
    "    d = (det(*line1), det(*line2))\n",
    "    x = det(d, xdiff) / div\n",
    "    y = det(d, ydiff) / div\n",
    "    return (x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_image(image, points):\n",
    "    # Convert the input points to a NumPy array\n",
    "    points = np.array(points, dtype=np.float32)\n",
    "\n",
    "    # Calculate the bounding box for the source region\n",
    "    min_x, min_y = np.min(points, axis=0)\n",
    "    max_x, max_y = np.max(points, axis=0)\n",
    "\n",
    "    # Calculate the aspect ratio of the source region\n",
    "    aspect_ratio = (max_x - min_x) / (max_y - min_y)\n",
    "\n",
    "    # Define the target rectangle based on the aspect ratio\n",
    "    target_height = 300  # Adjust this value based on your preference\n",
    "    target_width = int(target_height * aspect_ratio)\n",
    "\n",
    "    target_rect = np.array([[0, 0], [target_width, 0], [target_width, target_height], [0, target_height]], dtype=np.float32)\n",
    "\n",
    "    # Calculate the perspective transformation matrix\n",
    "    matrix = cv2.getPerspectiveTransform(points, target_rect)\n",
    "\n",
    "    # Apply the perspective transformation\n",
    "    result = cv2.warpPerspective(image, matrix, (target_width, target_height))\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_text(binary_image):\n",
    "    # Specify the OCR engine mode\n",
    "    custom_config = r'--oem 3 --psm 6'\n",
    "\n",
    "    # Perform OCR on the preprocessed image\n",
    "    text = pytesseract.image_to_string(binary_image, config=custom_config)\n",
    "    print(\"OCR Output:\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OCR Output: ASAA-017\n",
      "\n",
      "OCR Output: AMAA 302\n",
      "\n",
      "OCR Output: AMSAA-489\n",
      "\n",
      "OCR Output: 7\n",
      "Mi\n",
      "\n",
      "OCR Output: AASAB-264\n",
      "\n",
      "OCR Output: AA®AB-297\n",
      "\n",
      "OCR Output: ANMAB-74)\n",
      "\n",
      "OCR Output: AN AB-767\n",
      "\n",
      "OCR Output: AN AB-767\n",
      "\n",
      "OCR Output: ASAB-949\n",
      "\n",
      "OCR Output: \n",
      "OCR Output: AeAD-040\n",
      "\n",
      "OCR Output: ANAD-336\n",
      "\n",
      "OCR Output: ASAN.27,\n",
      "\n",
      "OCR Output: AASAD-374\n",
      "\n",
      "OCR Output: AASAD-446\n",
      "\n",
      "OCR Output: ANSAD-456\n",
      "\n",
      "OCR Output: ——S—t—ts\n",
      "\n",
      "OCR Output: AASAD-468\n",
      "\n",
      "OCR Output: ‘Va\n",
      "NG.\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\dkiovics\\Documents\\7_felev\\kepfeldolgozas\\hf\\licenceplatepro2000\\license_plate_detector.ipynb Cell 6\u001b[0m line \u001b[0;36m5\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dkiovics/Documents/7_felev/kepfeldolgozas/hf/licenceplatepro2000/license_plate_detector.ipynb#X12sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m concatenated \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mconcatenate((image1, image2, image3), axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dkiovics/Documents/7_felev/kepfeldolgozas/hf/licenceplatepro2000/license_plate_detector.ipynb#X12sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m cv2\u001b[39m.\u001b[39mimshow(\u001b[39m'\u001b[39m\u001b[39mAll\u001b[39m\u001b[39m'\u001b[39m, concatenated)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/dkiovics/Documents/7_felev/kepfeldolgozas/hf/licenceplatepro2000/license_plate_detector.ipynb#X12sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m cv2\u001b[39m.\u001b[39;49mwaitKey(\u001b[39m0\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dkiovics/Documents/7_felev/kepfeldolgozas/hf/licenceplatepro2000/license_plate_detector.ipynb#X12sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m cv2\u001b[39m.\u001b[39mdestroyAllWindows()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Get the bounding lines and show them on the image. Do this for all images in the folder\n",
    "for filename in os.listdir('cropped'):\n",
    "    image = cv2.imread('cropped/' + filename, 0)\n",
    "    h, v = get_bounding_lines(image, 15, 70, 60, 32)\n",
    "    \n",
    "    if h is None or v is None:\n",
    "        print(filename + '  :  failed to find bounding lines')\n",
    "        continue\n",
    "\n",
    "    # Show the lines on the image\n",
    "    image1 = image.copy()\n",
    "    cv2.line(image1, (h[0], h[1]), (h[2], h[3]), 255, 2)\n",
    "    cv2.line(image1, (h[4], h[5]), (h[6], h[7]), 255, 2)\n",
    "    cv2.line(image1, (v[0], v[1]), (v[2], v[3]), 255, 2)\n",
    "    cv2.line(image1, (v[4], v[5]), (v[6], v[7]), 255, 2)\n",
    "    \n",
    "    # Get the intersection points\n",
    "    p1 = line_intersection(((h[0], h[1]), (h[2], h[3])), ((v[0], v[1]), (v[2], v[3])))\n",
    "    p2 = line_intersection(((h[0], h[1]), (h[2], h[3])), ((v[4], v[5]), (v[6], v[7])))\n",
    "    p3 = line_intersection(((h[4], h[5]), (h[6], h[7])), ((v[4], v[5]), (v[6], v[7])))\n",
    "    p4 = line_intersection(((h[4], h[5]), (h[6], h[7])), ((v[0], v[1]), (v[2], v[3])))\n",
    "\n",
    "    image2 = image.copy()\n",
    "    # Show the points on the image\n",
    "    cv2.circle(image2, (int(p1[0]), int(p1[1])), 3, 255, -1)\n",
    "    cv2.circle(image2, (int(p2[0]), int(p2[1])), 3, 255, -1)\n",
    "    cv2.circle(image2, (int(p3[0]), int(p3[1])), 3, 255, -1)\n",
    "    cv2.circle(image2, (int(p4[0]), int(p4[1])), 3, 255, -1)\n",
    "\n",
    "    # Get the rectangle image\n",
    "    image3 = transform_image(image, [p1, p2, p3, p4])\n",
    "    \n",
    "    #scale all 3 images to a fixed width\n",
    "    width = 300\n",
    "    image1 = cv2.resize(image1, (width, int(image1.shape[0] * width / image1.shape[1])))\n",
    "    image2 = cv2.resize(image2, (width, int(image2.shape[0] * width / image2.shape[1])))\n",
    "    image3 = cv2.resize(image3, (width, int(image3.shape[0] * width / image3.shape[1])))\n",
    "\n",
    "    # Make all images rgb\n",
    "    image1 = cv2.cvtColor(image1, cv2.COLOR_GRAY2RGB)\n",
    "    image2 = cv2.cvtColor(image2, cv2.COLOR_GRAY2RGB)\n",
    "    image3 = cv2.cvtColor(image3, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "    # Insert a red line at the bottom of each image\n",
    "    image1 = cv2.line(image1, (0, image1.shape[0] - 1), (image1.shape[1] - 1, image1.shape[0] - 1), (0, 0, 255), 2)\n",
    "    image2 = cv2.line(image2, (0, image2.shape[0] - 1), (image2.shape[1] - 1, image2.shape[0] - 1), (0, 0, 255), 2)\n",
    "    image3 = cv2.line(image3, (0, image3.shape[0] - 1), (image3.shape[1] - 1, image3.shape[0] - 1), (0, 0, 255), 2)\n",
    "\n",
    "    # Perform OCR on the rectangle image\n",
    "    detect_text(image3)\n",
    "\n",
    "    # Show all three images in one line as the output of the cell\n",
    "    concatenated = np.concatenate((image1, image2, image3), axis=0)\n",
    "    cv2.imshow('All', concatenated)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
